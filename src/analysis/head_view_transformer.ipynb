{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from transformer.Models import Transformer\n",
    "from transformer.Translator import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'save_model_path': '../models/DNPG_base_transformer_bert_tokenizer_bert_bow_indivtopk.pth', 'log_file': '../logs/DNPG_base_transformer_bert_tokenizer_training_bert_bow_indiv_topk.txt', 'test_output_file': '../outputs/test_DNPG_transformer_bert_tokenizer_bow_indivtopk_out.txt', 'val_output_file': '../outputs/val_DNPG_transformer_bert_tokenizer_bow_indivtopk_out.txt', 'dataset': 'quora_bert_mask_predict_dataset', 'num_epochs': 50, 'batch_size': 100, 'd_model': 450, 'd_inner_hid': 512, 'd_k': 50, 'd_v': 50, 'n_head': 9, 'n_layers': 3, 'n_warmup_steps': 8000, 'dropout': 0.1, 'embs_share_weight': True, 'proj_share_weight': True, 'label_smoothing': False, 'train_size': 100000, 'val_size': 4000, 'test_size': 20000, 'is_bow': True, 'bow_strategy': 'indiv_topk', 'indiv_topk': 10, 'topk': 50, 'lr': '5e-4'}\n"
     ]
    }
   ],
   "source": [
    "##### Read Arguments from Config File #####\n",
    "\n",
    "# config_path = '../configs/dpng_transformer_bert_tokenizer.yaml'\n",
    "# config_path = '../configs/dpng_transformer_bert_tokenizer_bow.yaml'\n",
    "config_path = '../configs/dpng_transformer_bert_tokenizer_bow_indivtopk.yaml'\n",
    "# config_path = '../configs/dpng_transformer_bert_tokenizer_bow_indivtopk_onlybow.yaml'\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    print(config)\n",
    "\n",
    "save_model_path = config['save_model_path']\n",
    "output_file = config['test_output_file']\n",
    "use_dataset = config['dataset']\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "d_model = config['d_model']\n",
    "d_inner_hid = config['d_inner_hid']\n",
    "d_k = config['d_k']\n",
    "d_v = config['d_v']\n",
    "\n",
    "n_head = config['n_head']\n",
    "n_layers = config['n_layers']\n",
    "n_warmup_steps = config['n_warmup_steps']\n",
    "\n",
    "dropout = config['dropout']\n",
    "embs_share_weight = config['embs_share_weight']\n",
    "proj_share_weight = config['proj_share_weight']\n",
    "label_smoothing = config['label_smoothing']\n",
    "\n",
    "train_size = config['train_size']\n",
    "val_size = config['val_size']\n",
    "test_size = config['test_size']\n",
    "\n",
    "beam_size = 3\n",
    "max_seq_len = 30\n",
    "\n",
    "try:\n",
    "    is_bow = config['is_bow']\n",
    "\n",
    "    if is_bow:\n",
    "        bow_strategy = config['bow_strategy']\n",
    "        topk = config['topk']\n",
    "        if bow_strategy != 'simple_sum':\n",
    "            indiv_topk = config['indiv_topk']\n",
    "        else:\n",
    "            # not used but use default value for simplicity\n",
    "            indiv_topk = 50\n",
    "\n",
    "except KeyError:\n",
    "    is_bow = False\n",
    "    \n",
    "try:\n",
    "    only_bow = config['only_bow']\n",
    "except KeyError:\n",
    "    only_bow = False \n",
    "# ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = True\n",
    "# load dataset\n",
    "if preprocessed:\n",
    "    from datasets.quora_preprocessed_dataset import QuoraPreprocessedDataset as Dataset\n",
    "else:\n",
    "    if use_dataset == 'quora_dataset':\n",
    "        from datasets.quora_dataset import QuoraDataset as Dataset\n",
    "    elif use_dataset == 'quora_bert_dataset':\n",
    "        from datasets.quora_bert_dataset import QuoraBertDataset as Dataset\n",
    "    elif use_dataset == 'quora_bert_mask_predict_dataset':\n",
    "        from datasets.quora_bert_mask_predict_dataset import QuoraBertMaskPredictDataset as Dataset\n",
    "    elif use_dataset == 'quora_word_mask_prediction_dataset':\n",
    "        from datasets.quora_word_mask_prediction_dataset import QuoraWordMaskPredictDataset as Dataset\n",
    "    else:\n",
    "        raise NotImplementedError(\"Dataset is not defined or not implemented\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    seq1_tensors = [s[0] for s in samples]\n",
    "    seq2_tensors = [s[1] for s in samples]\n",
    "\n",
    "    # zero pad\n",
    "    seq1_tensors = pad_sequence(seq1_tensors,\n",
    "                                  batch_first=True)\n",
    "\n",
    "    seq2_tensors = pad_sequence(seq2_tensors,\n",
    "                                  batch_first=True)    \n",
    "    \n",
    "    return seq1_tensors, seq2_tensors\n",
    "\n",
    "\n",
    "if preprocessed:\n",
    "    model_name = config_path.split('/')[-1][:-5]\n",
    "    preprocessed_file = '../data/preprocess_all_{}.npy'.format(model_name)\n",
    "    dataset = Dataset(\"test\", train_size, val_size, test_size, preprocessed_file=preprocessed_file)\n",
    "elif is_bow:\n",
    "    dataset = Dataset(\"test\", train_size, val_size, test_size, bow_strategy=bow_strategy, topk=topk, indiv_topk=indiv_topk, only_bow=only_bow)\n",
    "else:\n",
    "    dataset = Dataset(\"test\", train_size, val_size, test_size)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=create_mini_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transformer = Transformer(\n",
    "    dataset.n_words,\n",
    "    dataset.n_words,\n",
    "    src_pad_idx=dataset.PAD_token_id,\n",
    "    trg_pad_idx=dataset.PAD_token_id,\n",
    "    trg_emb_prj_weight_sharing=proj_share_weight,\n",
    "    emb_src_trg_weight_sharing=embs_share_weight,\n",
    "    d_k=d_k,\n",
    "    d_v=d_v,\n",
    "    d_model=d_model,\n",
    "    d_word_vec=d_model,\n",
    "    d_inner=d_inner_hid,\n",
    "    n_layers=n_layers,\n",
    "    n_head=n_head,\n",
    "    dropout=dropout    \n",
    ")\n",
    "\n",
    "model = transformer.to(device)\n",
    "\n",
    "model.load_state_dict((torch.load(\n",
    "        save_model_path, map_location=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = dataset.PAD_token_id\n",
    "trg_pad_idx = dataset.PAD_token_id\n",
    "    \n",
    "trg_bos_idx = dataset.SOS_token_id\n",
    "trg_eos_idx = dataset.EOS_token_id\n",
    "unk_idx = dataset.UNK_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1, seq2 = next(iter(data_loader))\n",
    "src_seq = seq1.to(device)\n",
    "trg_seq = seq2[:, :-1].to(device)\n",
    "pred = model(src_seq, trg_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 28996])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 'bert-base-uncased'\n",
    "do_lower_case = True\n",
    "model = BertModel.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_version, do_lower_case=do_lower_case)\n",
    "sentence_a = \"The cat sat on the mat\"\n",
    "sentence_b = \"The cat lay on the rug\"\n",
    "show_head_view(model, tokenizer, sentence_a, sentence_b)\n",
    "\n",
    "def show_head_view(model, tokenizer, sentence_a, sentence_b=None):\n",
    "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    if sentence_b:\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
    "        sentence_b_start = token_type_ids[0].tolist().index(1)\n",
    "    else:\n",
    "        attention = model(input_ids)[-1]\n",
    "        sentence_b_start = None\n",
    "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)    \n",
    "    head_view(attention, tokens, sentence_b_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
