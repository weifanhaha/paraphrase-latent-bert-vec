{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from transformer.CustomModels import Transformer, Translator\n",
    "from datasets.quora_bert_mask_predict_prob_dataset import QuoraBertMaskPredictProbDataset\n",
    "from datasets.quora_text_dataset import QuoraTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'save_model_path': '../models/transformer_bert_enc_attention.pth', 'log_file': '../logs/transformer_bert_enc_attention.txt', 'test_output_file': '../outputs/test_transformer_bert_enc_attention.txt', 'val_output_file': '../outputs/val_transformer_bert_enc_attention.txt', 'preprocessed_folder': '../data/preprocess_quora_bert_mask_predict/', 'dataset': 'quora_bert_dataset', 'num_epochs': 50, 'batch_size': 50, 'd_model': 450, 'd_inner_hid': 512, 'd_k': 50, 'd_v': 50, 'n_head': 9, 'n_layers': 3, 'n_warmup_steps': 24000, 'dropout': 0.1, 'embs_share_weight': True, 'proj_share_weight': True, 'label_smoothing': False, 'train_size': 100000, 'val_size': 4000, 'test_size': 20000, 'is_bow': False, 'lr': '1e-3'}\n"
     ]
    }
   ],
   "source": [
    "##### Read Arguments from Config File #####\n",
    "\n",
    "config_path = '../configs/dpng_transformer_bert_attention.yaml'\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "print(config)\n",
    "\n",
    "save_model_path = config['save_model_path']\n",
    "save_model_path = '../models/tune/transformer_bert_enc_attention_alpha0.5.pth'\n",
    "log_file = config['log_file']\n",
    "output_file = config['test_output_file']\n",
    "preprocessed_folder = config['preprocessed_folder']\n",
    "\n",
    "num_epochs = config['num_epochs']\n",
    "\n",
    "\n",
    "d_model = config['d_model']\n",
    "d_inner_hid = config['d_inner_hid']\n",
    "d_k = config['d_k']\n",
    "d_v = config['d_v']\n",
    "\n",
    "n_head = config['n_head']\n",
    "n_layers = config['n_layers']\n",
    "n_warmup_steps = config['n_warmup_steps']\n",
    "\n",
    "dropout = config['dropout']\n",
    "embs_share_weight = config['embs_share_weight']\n",
    "proj_share_weight = config['proj_share_weight']\n",
    "label_smoothing = config['label_smoothing']\n",
    "\n",
    "train_size = config['train_size']\n",
    "val_size = config['val_size']\n",
    "test_size = config['test_size']\n",
    "\n",
    "beam_size = 3\n",
    "max_seq_len = 30\n",
    "batch_size = 1\n",
    "\n",
    "# ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_alpha = 0.5 # half-half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    seq1_tensors = [s[0] for s in samples]\n",
    "    seq2_tensors = [s[1] for s in samples]\n",
    "    probs_tensors = [s[2] for s in samples]\n",
    "\n",
    "    # zero pad\n",
    "    seq1_tensors = pad_sequence(seq1_tensors,\n",
    "                                  batch_first=True)\n",
    "\n",
    "    seq2_tensors = pad_sequence(seq2_tensors,\n",
    "                                  batch_first=True)\n",
    "    probs_tensors = pad_sequence(probs_tensors,\n",
    "                                  batch_first=True)\n",
    "    \n",
    "    return seq1_tensors, seq2_tensors, probs_tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149263\n"
     ]
    }
   ],
   "source": [
    "dataset = QuoraBertMaskPredictProbDataset(\"test\", train_size, val_size, test_size, preprocessed_folder=preprocessed_folder)\n",
    "# dataset = QuoraBertMaskPredictProbDataset(\"test\", train_size, val_size, test_size)\n",
    "text_dataset = QuoraTextDataset(\"test\", train_size, val_size, test_size)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=create_mini_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Who are the top ten astrologers in India ?', 'Who are the top ten Indian astrologers ? ')\n",
      "['[CLS]', 'Who', 'are', 'the', 'top', 'ten', 'as', '##tro', '##log', '##ers', 'in', 'India', '?', '[SEP]']\n",
      "['[CLS]', 'Who', 'are', 'the', 'top', 'ten', 'Indian', 'as', '##tro', '##log', '##ers', '?', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# text_dataset[0]\n",
    "i = 5\n",
    "idxs, idxs2, probs = dataset[i]\n",
    "print(text_dataset[i])\n",
    "print(dataset.tokenizer.convert_ids_to_tokens(idxs))\n",
    "print(dataset.tokenizer.convert_ids_to_tokens(idxs2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transformer = Transformer(\n",
    "    dataset.n_words,\n",
    "    dataset.n_words,\n",
    "    src_pad_idx=dataset.PAD_token_id,\n",
    "    trg_pad_idx=dataset.PAD_token_id,\n",
    "    trg_emb_prj_weight_sharing=proj_share_weight,\n",
    "    emb_src_trg_weight_sharing=embs_share_weight,\n",
    "    d_k=d_k,\n",
    "    d_v=d_v,\n",
    "    d_model=d_model,\n",
    "    d_word_vec=d_model,\n",
    "    d_inner=d_inner_hid,\n",
    "    n_layers=n_layers,\n",
    "    n_head=n_head,\n",
    "    dropout=dropout,\n",
    "    bert_alpha=bert_alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = transformer.to(device)\n",
    "\n",
    "model.load_state_dict((torch.load(\n",
    "        save_model_path, map_location=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = dataset.PAD_token_id\n",
    "trg_pad_idx = dataset.PAD_token_id\n",
    "    \n",
    "trg_bos_idx = dataset.SOS_token_id\n",
    "trg_eos_idx = dataset.EOS_token_id\n",
    "unk_idx = dataset.UNK_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(\n",
    "        model=model,\n",
    "        beam_size=beam_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "        src_pad_idx=src_pad_idx,\n",
    "        trg_pad_idx=trg_pad_idx,\n",
    "        trg_bos_idx=trg_bos_idx,\n",
    "        trg_eos_idx=trg_eos_idx,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1, seq2, bert_prob = next(iter(data_loader))\n",
    "input_seq = seq1.to(device)\n",
    "bert_prob = bert_prob.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seq = translator.translate_sentence(input_seq, bert_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'What',\n",
       " 'are',\n",
       " 'some',\n",
       " 'good',\n",
       " 'side',\n",
       " 'dishes',\n",
       " 'for',\n",
       " 'a',\n",
       " 'healthy',\n",
       " 'time',\n",
       " '?',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tokenizer.convert_ids_to_tokens(pred_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "torch.Size([1, 18, 28996])\n"
     ]
    }
   ],
   "source": [
    "print(input_seq.shape)\n",
    "print(bert_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 1591/20000 [04:34<52:55,  5.80it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-64185a5be695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrg_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpred_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpred_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_ids_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpred_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-da311217d4d2>\u001b[0m in \u001b[0;36mtranslate_sentence\u001b[0;34m(self, src_seq, bert_out, return_attn)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m#     pred_seq = translator.translate_sentence(src_seq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pad_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_pad_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_init_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0moutput_dec_enc_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_enc_attn_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-da311217d4d2>\u001b[0m in \u001b[0;36m_get_init_state\u001b[0;34m(self, src_seq, src_mask, bert_out)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mbest_k_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_k_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-da311217d4d2>\u001b[0m in \u001b[0;36m_model_decode\u001b[0;34m(self, trg_seq, enc_output, bert_out, src_mask)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#         dec_output, *_ = self.model.decoder(trg_seq, trg_mask, enc_output, src_mask, return_attns=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mbert_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mdec_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_slf_attn_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_attns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_word_prj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my_paraphrase_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-d4f8852f2f6e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, trg_seq, trg_mask, enc_output, bert_out, src_mask, return_attns)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdec_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             dec_output, dec_slf_attn, dec_enc_attn = dec_layer(\n\u001b[0;32m---> 32\u001b[0;31m                 dec_output, enc_output, bert_out, slf_attn_mask=trg_mask, dec_enc_attn_mask=src_mask)\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mdec_slf_attn_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdec_slf_attn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_attns\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdec_enc_attn_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdec_enc_attn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_attns\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/my_paraphrase_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-33bc3916ee87>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dec_input, enc_output, bert_out, slf_attn_mask, dec_enc_attn_mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m             dec_output, bert_out, enc_output, mask=dec_enc_attn_mask)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_alpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0mdec_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_alpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdec_bert_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = dataset.tokenizer\n",
    "# count = 0\n",
    "with open(output_file, 'w') as f:\n",
    "    for i, (seq1, seq2, bert_prob) in enumerate(tqdm(data_loader)):\n",
    "        src_line, trg_line = text_dataset.sentences[i]\n",
    "\n",
    "        input_seq = seq1.to(device)\n",
    "        bert_prob = bert_prob.to(device)\n",
    "        trg_seq = seq2[0].tolist()\n",
    "\n",
    "        pred_seq = translator.translate_sentence(input_seq, bert_prob)\n",
    "        pred_tokens = tokenizer.convert_ids_to_tokens(pred_seq)\n",
    "        pred_line = tokenizer.convert_tokens_to_string(pred_tokens)\n",
    "        pred_line = pred_line.replace(dataset.SOS_token, '').replace(dataset.EOS_token, '')\n",
    "\n",
    "        input_tokens = tokenizer.convert_ids_to_tokens(input_seq[0].tolist())\n",
    "        input_line = tokenizer.convert_tokens_to_string(input_tokens)\n",
    "\n",
    "        trg_tokens = tokenizer.convert_ids_to_tokens(trg_seq)\n",
    "        trg_line = tokenizer.convert_tokens_to_string(trg_tokens)\n",
    "        trg_line = trg_line.replace(dataset.SOS_token, '').replace(dataset.EOS_token, '')\n",
    "\n",
    "\n",
    "#         print('*' * 80)\n",
    "#         print('Source: ', src_line.strip())\n",
    "#         print('Target: ', trg_line.strip())\n",
    "#         print('Input: ', input_line.strip())\n",
    "#         print('Predict: ', pred_line.strip())\n",
    "        \n",
    "        f.write('*' * 80)\n",
    "        f.write('\\n')\n",
    "        f.write('Source: {}\\n'.format(src_line.strip()))\n",
    "        f.write('Target: {}\\n'.format(trg_line.strip()))\n",
    "        f.write('Input: {}\\n'.format(input_line.strip()))\n",
    "        f.write('Predict: {}\\n'.format(pred_line.strip()))\n",
    "        f.flush()\n",
    "\n",
    "#         count += 1\n",
    "#         if count > 5:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-12b44fc90e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "output_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
