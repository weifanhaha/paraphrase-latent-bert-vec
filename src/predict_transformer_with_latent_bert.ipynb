{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from transformer.CustomModels import Transformer, Translator\n",
    "from datasets.quora_bert_mask_predict_prob_dataset import QuoraBertMaskPredictProbDataset\n",
    "from datasets.quora_text_dataset import QuoraTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'save_model_path': '../models/transformer_bert_enc_attention.pth', 'log_file': '../logs/transformer_bert_enc_attention.txt', 'test_output_file': '../outputs/test_transformer_bert_enc_attention.txt', 'val_output_file': '../outputs/val_transformer_bert_enc_attention.txt', 'preprocessed_folder': '../data/preprocess_quora_bert_mask_predict/', 'dataset': 'quora_bert_dataset', 'num_epochs': 50, 'batch_size': 50, 'd_model': 450, 'd_inner_hid': 512, 'd_k': 50, 'd_v': 50, 'n_head': 9, 'n_layers': 3, 'n_warmup_steps': 24000, 'dropout': 0.1, 'embs_share_weight': True, 'proj_share_weight': True, 'label_smoothing': False, 'train_size': 100000, 'val_size': 4000, 'test_size': 20000, 'is_bow': False, 'lr': '1e-3'}\n"
     ]
    }
   ],
   "source": [
    "##### Read Arguments from Config File #####\n",
    "\n",
    "config_path = '../configs/dpng_transformer_bert_attention.yaml'\n",
    "\n",
    "with open(config_path) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "print(config)\n",
    "\n",
    "save_model_path = config['save_model_path']\n",
    "save_model_path = '../models/tune/transformer_bert_enc_attention_alpha0.5.pth'\n",
    "log_file = config['log_file']\n",
    "output_file = config['test_output_file']\n",
    "preprocessed_folder = config['preprocessed_folder']\n",
    "\n",
    "num_epochs = config['num_epochs']\n",
    "\n",
    "\n",
    "d_model = config['d_model']\n",
    "d_inner_hid = config['d_inner_hid']\n",
    "d_k = config['d_k']\n",
    "d_v = config['d_v']\n",
    "\n",
    "n_head = config['n_head']\n",
    "n_layers = config['n_layers']\n",
    "n_warmup_steps = config['n_warmup_steps']\n",
    "\n",
    "dropout = config['dropout']\n",
    "embs_share_weight = config['embs_share_weight']\n",
    "proj_share_weight = config['proj_share_weight']\n",
    "label_smoothing = config['label_smoothing']\n",
    "\n",
    "train_size = config['train_size']\n",
    "val_size = config['val_size']\n",
    "test_size = config['test_size']\n",
    "\n",
    "beam_size = 3\n",
    "max_seq_len = 30\n",
    "batch_size = 1\n",
    "\n",
    "# ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_alpha = 0.5 # half-half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batch(samples):\n",
    "    seq1_tensors = [s[0] for s in samples]\n",
    "    seq2_tensors = [s[1] for s in samples]\n",
    "    probs_tensors = [s[2] for s in samples]\n",
    "\n",
    "    # zero pad\n",
    "    seq1_tensors = pad_sequence(seq1_tensors,\n",
    "                                  batch_first=True)\n",
    "\n",
    "    seq2_tensors = pad_sequence(seq2_tensors,\n",
    "                                  batch_first=True)\n",
    "    probs_tensors = pad_sequence(probs_tensors,\n",
    "                                  batch_first=True)\n",
    "    \n",
    "    return seq1_tensors, seq2_tensors, probs_tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149263\n"
     ]
    }
   ],
   "source": [
    "dataset = QuoraBertMaskPredictProbDataset(\"test\", train_size, val_size, test_size, preprocessed_folder=preprocessed_folder)\n",
    "# dataset = QuoraBertMaskPredictProbDataset(\"test\", train_size, val_size, test_size)\n",
    "text_dataset = QuoraTextDataset(\"test\", train_size, val_size, test_size)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=create_mini_batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Who are the top ten astrologers in India ?', 'Who are the top ten Indian astrologers ? ')\n",
      "['[CLS]', 'Who', 'are', 'the', 'top', 'ten', 'as', '##tro', '##log', '##ers', 'in', 'India', '?', '[SEP]']\n",
      "['[CLS]', 'Who', 'are', 'the', 'top', 'ten', 'Indian', 'as', '##tro', '##log', '##ers', '?', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# text_dataset[0]\n",
    "i = 5\n",
    "idxs, idxs2, probs = dataset[i]\n",
    "print(text_dataset[i])\n",
    "print(dataset.tokenizer.convert_ids_to_tokens(idxs))\n",
    "print(dataset.tokenizer.convert_ids_to_tokens(idxs2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transformer = Transformer(\n",
    "    dataset.n_words,\n",
    "    dataset.n_words,\n",
    "    src_pad_idx=dataset.PAD_token_id,\n",
    "    trg_pad_idx=dataset.PAD_token_id,\n",
    "    trg_emb_prj_weight_sharing=proj_share_weight,\n",
    "    emb_src_trg_weight_sharing=embs_share_weight,\n",
    "    d_k=d_k,\n",
    "    d_v=d_v,\n",
    "    d_model=d_model,\n",
    "    d_word_vec=d_model,\n",
    "    d_inner=d_inner_hid,\n",
    "    n_layers=n_layers,\n",
    "    n_head=n_head,\n",
    "    dropout=dropout,\n",
    "    bert_alpha=bert_alpha\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = transformer.to(device)\n",
    "\n",
    "model.load_state_dict((torch.load(\n",
    "        save_model_path, map_location=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = dataset.PAD_token_id\n",
    "trg_pad_idx = dataset.PAD_token_id\n",
    "    \n",
    "trg_bos_idx = dataset.SOS_token_id\n",
    "trg_eos_idx = dataset.EOS_token_id\n",
    "unk_idx = dataset.UNK_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(\n",
    "        model=model,\n",
    "        beam_size=beam_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "        src_pad_idx=src_pad_idx,\n",
    "        trg_pad_idx=trg_pad_idx,\n",
    "        trg_bos_idx=trg_bos_idx,\n",
    "        trg_eos_idx=trg_eos_idx,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dry-run\n",
    "seq1, seq2, bert_prob = next(iter(data_loader))\n",
    "input_seq = seq1.to(device)\n",
    "bert_prob = bert_prob.to(device)\n",
    "pred_seq = translator.translate_sentence(input_seq, bert_prob)\n",
    "print(dataset.tokenizer.convert_ids_to_tokens(pred_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [57:18<00:00,  5.82it/s]  \n"
     ]
    }
   ],
   "source": [
    "tokenizer = dataset.tokenizer\n",
    "# count = 0\n",
    "with open(output_file, 'w') as f:\n",
    "    for i, (seq1, seq2, bert_prob) in enumerate(tqdm(data_loader)):\n",
    "        src_line, trg_line = text_dataset.sentences[i]\n",
    "\n",
    "        input_seq = seq1.to(device)\n",
    "        bert_prob = bert_prob.to(device)\n",
    "        trg_seq = seq2[0].tolist()\n",
    "\n",
    "        pred_seq = translator.translate_sentence(input_seq, bert_prob)\n",
    "        pred_tokens = tokenizer.convert_ids_to_tokens(pred_seq)\n",
    "        pred_line = tokenizer.convert_tokens_to_string(pred_tokens)\n",
    "        pred_line = pred_line.replace(dataset.SOS_token, '').replace(dataset.EOS_token, '')\n",
    "\n",
    "        input_tokens = tokenizer.convert_ids_to_tokens(input_seq[0].tolist())\n",
    "        input_line = tokenizer.convert_tokens_to_string(input_tokens)\n",
    "\n",
    "        trg_tokens = tokenizer.convert_ids_to_tokens(trg_seq)\n",
    "        trg_line = tokenizer.convert_tokens_to_string(trg_tokens)\n",
    "        trg_line = trg_line.replace(dataset.SOS_token, '').replace(dataset.EOS_token, '')\n",
    "\n",
    "\n",
    "#         print('*' * 80)\n",
    "#         print('Source: ', src_line.strip())\n",
    "#         print('Target: ', trg_line.strip())\n",
    "#         print('Input: ', input_line.strip())\n",
    "#         print('Predict: ', pred_line.strip())\n",
    "        \n",
    "        f.write('*' * 80)\n",
    "        f.write('\\n')\n",
    "        f.write('Source: {}\\n'.format(src_line.strip()))\n",
    "        f.write('Target: {}\\n'.format(trg_line.strip()))\n",
    "        f.write('Input: {}\\n'.format(input_line.strip()))\n",
    "        f.write('Predict: {}\\n'.format(pred_line.strip()))\n",
    "        f.flush()\n",
    "\n",
    "#         count += 1\n",
    "#         if count > 5:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
