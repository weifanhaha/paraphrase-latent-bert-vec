{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('./*txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open(files[0])\n",
    "# lines = f.read()\n",
    "# examples = lines.split('********************************************************************************')\n",
    "# examples = examples[1:] # the first one is empty\n",
    "# ex = examples[1]\n",
    "# ex.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_analyze = [\n",
    "#     './test_DNPG_base_transformer.txt',\n",
    "#     './test_DNPG_base_transformer_wordnet.txt',\n",
    "#     './test_DNPG_base_transformer_wordnet_replace_nopreprocess.txt',\n",
    "#     './test_DNPG_transformer_bert_tokenizer_bow_out.txt',\n",
    "#     './test_DNPG_transformer_bert_tokenizer_bow_indivtopk_out.txt',\n",
    "#     './test_DNPG_transformer_bert_tokenizer_bow_indivtopk_onlybow_out.txt',\n",
    "#     './test_DNPG_transformer_bert_tokenizer_bow_indivtopk_replace_out_nopreprocess.txt',\n",
    "#     './test_DNPG_transformer_bert_tokenizer_bow_indivtopk_replace_out_nopreprocess_noreplace_test.txt',\n",
    "# ]\n",
    "\n",
    "# to_analyze = [\n",
    "#     './test_DNPG_transformer_bert_tokenizer_out.txt',\n",
    "#     './tune/test_DNPG_transformer_bert_tokenizer_with_classifier_out_lambda0.1.txt',\n",
    "#     './tune/test_DNPG_transformer_bert_tokenizer_with_classifier_out_lambda1.txt',\n",
    "#     './tune/test_DNPG_transformer_bert_tokenizer_with_classifier_out_lambda10.txt',\n",
    "#     './tune/test_DNPG_transformer_bert_tokenizer_with_classifier_out_lambda100.txt',\n",
    "#     './tune/test_DNPG_transformer_bert_tokenizer_with_classifier_out_lambda1000.txt'\n",
    "# ]\n",
    "\n",
    "\n",
    "# to_analyze = [\n",
    "#     './test_DNPG_base_transformer.txt',\n",
    "#     './test_DNPG_transformer_bert_tokenizer_out.txt',\n",
    "#     './test_DNPG_transformer_bert_tokenizer_bow_out.txt',\n",
    "#     './tune/transformer_key_enc_bert_val_attention_alpha0.5.txt',\n",
    "#     './tune/transformer_key_enc_bert_val_attention_alpha0.5_softmax.txt'\n",
    "# ]\n",
    "\n",
    "\n",
    "to_analyze = [\n",
    "    './fixseed/seed0/test_DNPG_base_transformer.txt',\n",
    "    './fixseed/seed0/transformer_key_enc_bert_val_attention_alpha0.5.txt',\n",
    "    './fixseed/seed777/test_DNPG_base_transformer.txt',\n",
    "    './fixseed/seed777/transformer_key_enc_bert_val_attention_alpha0.5.txt',\n",
    "    './fixseed/seed33333/test_DNPG_base_transformer.txt',\n",
    "    './fixseed/seed33333/transformer_key_enc_bert_val_attention_alpha0.5.txt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[# Info #] file name: ./fixseed/seed0/test_DNPG_base_transformer.txt\n",
      "\n",
      "Source: West Bengal is to the east of India . Why is it called West Bengal ?\n",
      "Target: West bengal is in east India . Then why is it named West ?\n",
      "Input: West Bengal is to the east of India . Why is it called West Bengal ?\n",
      "Predict: Why is the West Bengal called the West Bengal ?\n",
      "\n",
      "[# Info #] file name: ./fixseed/seed0/transformer_key_enc_bert_val_attention_alpha0.5.txt\n",
      "\n",
      "Source: Which is best book to learn programming ?\n",
      "Target: West bengal is in east India . Then why is it named West ?\n",
      "Input: [CLS] West Bengal is to the east of India . Why is it called West Bengal ? [SEP]\n",
      "Predict: Why is West Bengal called West Bengal ?\n",
      "\n",
      "[# Info #] file name: ./fixseed/seed777/test_DNPG_base_transformer.txt\n",
      "\n",
      "Source: Why is Saltwater Taffy candy imported in Italy ?\n",
      "Target: Why are saltwater taffy imported in Japan ?\n",
      "Input: Why is Saltwater Taffy candy imported in Italy ?\n",
      "Predict: Why is Saltwater taffy candy imported in South Korea ?\n",
      "\n",
      "[# Info #] file name: ./fixseed/seed777/transformer_key_enc_bert_val_attention_alpha0.5.txt\n",
      "\n",
      "Source: Why is Saltwater Taffy candy imported in Italy ?\n",
      "Target: Why are saltwater taffy imported in Japan ?\n",
      "Input: [CLS] Why is Saltwater Taffy candy imported in Italy ? [SEP]\n",
      "Predict: Why is Saltwater taffy candy imported in Czech Republic ?\n",
      "\n",
      "[# Info #] file name: ./fixseed/seed33333/test_DNPG_base_transformer.txt\n",
      "\n",
      "Source: How do I recover my Gmail email addresses ?\n",
      "Target: Is there any way to recover e mails that were deleted from a Gmail account ?\n",
      "Input: How do I recover my Gmail email addresses ?\n",
      "Predict: How do I recover my deleted email by my gmail account ?\n",
      "\n",
      "[# Info #] file name: ./fixseed/seed33333/transformer_key_enc_bert_val_attention_alpha0.5.txt\n",
      "\n",
      "Source: How do I recover my Gmail email addresses ?\n",
      "Target: Is there any way to recover e - mails that were deleted from a Gmail account ?\n",
      "Input: [CLS] How do I recover my Gmail email addresses ? [SEP]\n",
      "Predict: How do I recover my Gmail account back ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# base vs bert + bow:\n",
    "# usable idx: 0, 8, 12, 15, 31\n",
    "# failed case idx: 22, 26\n",
    "# final selected: 0, 15, 31\n",
    "\n",
    "# base vs wordnet\n",
    "\n",
    "# base vs + classifier\n",
    "# usable idx: 0, 1, 9, 15, 16, 31, 43(?), 45(?), 589, 65, 68, 78\n",
    "# failed: 34, 51, 53, 59, 71\n",
    "idx = 53\n",
    "\n",
    "for file in to_analyze:\n",
    "    print(\"[# Info #] file name: {}\\n\".format(file))\n",
    "    f = open(file)\n",
    "    lines = f.read()\n",
    "    examples = lines.split('********************************************************************************')\n",
    "    examples = examples[1:] # the first one is empty\n",
    "    example = examples[idx]\n",
    "    \n",
    "    sentences = example.strip().split('\\n')\n",
    "    for sentence in sentences:\n",
    "        print(sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # analyze wordnet\n",
    "\n",
    "# from nltk.corpus import wordnet \n",
    "# import random\n",
    "\n",
    "# sentence = 'What is the food you can eat every day for breakfast lunch and dinner ?'\n",
    "# words = sentence.split()\n",
    "\n",
    "# # indiv_k\n",
    "# indiv_k = 5\n",
    "# appends = []\n",
    "\n",
    "# new_sentence = []\n",
    "\n",
    "# for word in words:\n",
    "#     print(word)\n",
    "#     syn_set = []\n",
    "#     for syn in wordnet.synsets(word):\n",
    "#         syn_set = [l.name() for l in syn.lemmas() if ('_' not in l.name() and '-' not in l.name())]\n",
    "# #     print(syn_set)\n",
    "#     syn_set = set(syn_set)\n",
    "#     if word in syn_set:\n",
    "#         syn_set.remove(word)\n",
    "#     print(syn_set)\n",
    "    \n",
    "#     # need not to append\n",
    "#     if len(syn_set) == 0:\n",
    "#         new_sentence.append(word)\n",
    "#         continue\n",
    "        \n",
    "#     sampled_syn = random.sample(syn_set, 1)[0]\n",
    "#     new_sentence.append(sampled_syn)\n",
    "#     if len(syn_set) > indiv_k:\n",
    "#         syn_set = random.sample(syn_set, indiv_k)\n",
    "\n",
    "#     for syn in syn_set:\n",
    "#         appends.append(syn)\n",
    "#     # append original word\n",
    "#     appends.append(word)\n",
    "# print(appends)\n",
    "# print(new_sentence)\n",
    "# print(' '.join(new_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
